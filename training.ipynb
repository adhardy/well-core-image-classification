{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adhardy/well-core-image-classification/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SrQGaYXFH0z"
      },
      "source": [
        "# Imports and Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Y4D1sFFPAV",
        "outputId": "afe37dd9-c0f2-4add-97f8-e50a891d4bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlfRGKqOFH02"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKq7PbAcFH03"
      },
      "source": [
        "# helper function to show an image\n",
        "def matplotlib_imshow(img, one_channel=False, normalized=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    if normalized:\n",
        "        img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "#list full file paths from a directory\n",
        "def list_file_paths(dirs):\n",
        "    all_files_paths = []\n",
        "    for dir in dirs:\n",
        "        files = os.listdir(dir)\n",
        "        files_path = [os.path.join(dir, f) for f in files]\n",
        "        all_files_paths += files_path\n",
        "\n",
        "    return sorted(all_files_paths)\n",
        "\n",
        "def train_val_split(frac_train, image_paths):\n",
        "    image_paths = np.array(image_paths)\n",
        "    n_images = len(image_paths)\n",
        "\n",
        "#freeze model parameters\n",
        "def freeze(module: torch.nn.Module):\n",
        "    # module.eval()\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "#unfreeze model parameters   \n",
        "def unfreeze(module: torch.nn.Module):\n",
        "    # module.train()\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad_(True)\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "  return torch.sum(y == y_pred) / len(y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEvtPPeDFH04"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuihQ_AEFH05"
      },
      "source": [
        "N_CLASSES = 7\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kVfIVFNFH05"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6vgySDiFH06"
      },
      "source": [
        "class CoreSlices (torch.utils.data.Dataset):\n",
        "    def __init__(self, imgs, transform):\n",
        "        self.imgs = imgs\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = self.transform(Image.open(self.imgs[idx]))\n",
        "\n",
        "        #get the root name of the file (no file extension) and extract the label\n",
        "        label = int(os.path.splitext(os.path.basename(self.imgs[idx]))[0].split(\"_\")[-1])\n",
        "        \n",
        "        return img, torch.tensor(label)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "uiDVd7bWFH06"
      },
      "source": [
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), #TODO get values from dataset\n",
        "    #augmentation\n",
        "])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), #TODO get values from dataset\n",
        "])\n",
        "\n",
        "#get list of all images in directories\n",
        "image_dirs = [\"/content/drive/MyDrive/slices/\"]#,\"data/Core Images/21-20a- 1/\",\"data/Core Images/42-29- 6/\",\"data/Core Images/206-01- 2/\"]\n",
        "\n",
        "images = list_file_paths(image_dirs)\n",
        "\n",
        "images_train, images_val = train_test_split(images, train_size=0.8)\n",
        "images_val, images_test = train_test_split(images_val, train_size=0.5)\n",
        "\n",
        "slices = {}\n",
        "slices[\"train\"] = CoreSlices(images_train, train_transform)\n",
        "slices[\"val\"] = CoreSlices(images_train, train_transform)\n",
        "slices[\"test\"] = CoreSlices(images_train, test_transform)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLikWpSdFH07"
      },
      "source": [
        "# Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8RNg9rtFH08"
      },
      "source": [
        "dataloaders = {}\n",
        "dataloaders[\"train\"] = torch.utils.data.DataLoader(slices[\"train\"], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)\n",
        "dataloaders[\"val\"] = torch.utils.data.DataLoader(slices[\"val\"], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)\n",
        "dataloaders[\"test\"] = torch.utils.data.DataLoader(slices[\"test\"], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pr40pm_FH0-"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLCfJGtQFH0-"
      },
      "source": [
        "model = torchvision.models.resnet152(pretrained=True)\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=2048, out_features=  N_CLASSES),\n",
        ")\n",
        "\n",
        "freeze(model.conv1)\n",
        "freeze(model.bn1)\n",
        "freeze(model.maxpool)\n",
        "freeze(model.layer1)\n",
        "freeze(model.layer2)\n",
        "freeze(model.layer3)\n",
        "freeze(model.layer4)\n",
        "freeze(model.fc)\n",
        "freeze(model.avgpool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMHekB7bFH0_"
      },
      "source": [
        "# Runner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMnRKUFtFH0_"
      },
      "source": [
        "class Runner():\n",
        "    def __init__(self, model, optimizer, criterion, device, summarywriter=None, epoch_scheduler=None, batch_scheduler=None):\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        self.summarywriter = summarywriter\n",
        "        self.epoch_scheduler = epoch_scheduler\n",
        "        self.batch_scheduler = batch_scheduler\n",
        "\n",
        "        #TODO implement the class based metrics used int the AiCourse notebooks\n",
        "        self.metrics = {\n",
        "            \"train\":{\n",
        "                \"loss\":0,\n",
        "                \"accuracy\":0\n",
        "            },\n",
        "            \"val\":{\n",
        "                \"loss\":0,\n",
        "                \"accuracy\":0\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def predict(self, outputs):\n",
        "      return torch.argmax(outputs, dim=1)\n",
        "\n",
        "    def predict_proba(self, outputs):\n",
        "        return torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "    def train(self, dataloader, epoch):\n",
        "\n",
        "        #switch to train mode\n",
        "        self.model.train()\n",
        "        train_step = 0\n",
        "        \n",
        "        #loop over each sample\n",
        "        for X,y in dataloader:\n",
        "            train_step+=1\n",
        "\n",
        "            X,y = X.to(self.device), y.to(self.device)\n",
        "            outputs = model.forward(X)\n",
        "\n",
        "            y_pred = self.predict(outputs)\n",
        "            self.metrics[\"train\"][\"accuracy\"] += accuracy(y_pred, y)\n",
        "\n",
        "            # back prop\n",
        "            loss = self.criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            \n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            #run scheduler per step\n",
        "            if self.batch_scheduler:\n",
        "                self.batch_scheduler.step()\n",
        "            \n",
        "            self.metrics[\"train\"][\"loss\"] += loss\n",
        "\n",
        "            yield train_step, loss\n",
        "\n",
        "        #calculate final metrics \n",
        "        self.metrics[\"train\"][\"loss\"] = self.metrics[\"train\"][\"loss\"] / train_step\n",
        "        self.metrics[\"train\"][\"accuracy\"] = self.metrics[\"train\"][\"accuracy\"] / train_step\n",
        "\n",
        "        #output to tensorboard\n",
        "        if summarywriter:\n",
        "            self.summarywriter.add_scaler(\"loss/training\", self.metrics[\"train\"][\"loss\"], epoch)\n",
        "            self.summarywriter.add_scaler(\"accuracy/training\", self.metrics[\"train\"][\"accuracy\"], epoch)\n",
        "\n",
        "        #run scheduler per epoch\n",
        "        if self.epoch_scheduler:\n",
        "                    self.epoch_scheduler.step()\n",
        "    \n",
        "    def evaluate(self, dataloader, epoch):\n",
        "\n",
        "        self.model.eval()\n",
        "        val_step = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X,y in dataloader:\n",
        "                val_step+=1\n",
        "\n",
        "                X,y = X.to(self.device), y.to(self.device)\n",
        "                outputs = model.forward(X)\n",
        "\n",
        "                y_pred = self.predict(outputs)\n",
        "                self.metrics[\"val\"][\"accuracy\"] += accuracy(y_pred, y)\n",
        "\n",
        "                loss = self.criterion(outputs, y)\n",
        "                self.metrics[\"val\"][\"loss\"] += loss\n",
        "\n",
        "                yield val_step, loss\n",
        "\n",
        "        #calculate final metrics \n",
        "        self.metrics[\"val\"][\"loss\"] = self.metrics[\"val\"][\"loss\"] / train_step\n",
        "        self.metrics[\"val\"][\"accuracy\"] = self.metrics[\"val\"][\"accuracy\"] / train_step\n",
        "\n",
        "        #output to tensorboard\n",
        "        if summarywriter:\n",
        "            self.summarywriter.add_scaler(\"loss/evaluation\", self.metrics[\"evaluation\"][\"loss\"], epoch)\n",
        "            self.summarywriter.add_scaler(\"accuracy/evaluation\", self.metrics[\"evaluation\"][\"accuracy\"], epoch)\n",
        "\n",
        "    def fit(self, epochs, dataloaders):\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"EPOCH {epoch+1}\")\n",
        "            #TRAIN\n",
        "            for step, loss in self.train(dataloaders[\"train\"], epoch):\n",
        "                print(f\"Training - Step: {step} Loss: {loss.item()}\")\n",
        "            \n",
        "            #EVALUATE\n",
        "            for step, loss in self.evaluate(dataloaders[\"validation\"], epoch):\n",
        "                print(f\"Validation - Step: {step}| Loss: {loss.item()}\")\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWoAkzmlFH0_"
      },
      "source": [
        "# Run and Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Gjd5IGFH1A"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summarywriter = SummaryWriter()\n",
        "runner = Runner(model, optimizer, criterion, device, summarywriter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ0ZYLcRFH1A"
      },
      "source": [
        "epochs = 10\n",
        "runner.fit(epochs, dataloaders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owSYtlySFH1B"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}