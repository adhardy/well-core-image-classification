{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0d504e65763db0712997c5abf4e36f31acc377fe14fcbb9335ac404214f57dc0f",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports and Helper Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "def matplotlib_imshow(img, one_channel=False, normalized=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    if normalized:\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "#list full file paths from a directory\n",
    "def list_file_paths(dirs):\n",
    "    all_files_paths = []\n",
    "    for dir in dirs:\n",
    "        files = os.listdir(dir)\n",
    "        files_path = [os.path.join(dir, f) for f in files]\n",
    "        all_files_paths += files_path\n",
    "\n",
    "    return sorted(all_files_paths)\n",
    "\n",
    "def train_val_split(frac_train, image_paths):\n",
    "    image_paths = np.array(image_paths)\n",
    "    n_images = len(image_paths)\n",
    "\n",
    "#freeze model parameters\n",
    "def freeze(module: torch.nn.Module):\n",
    "    # module.eval()\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "#unfreeze model parameters   \n",
    "def unfreeze(module: torch.nn.Module):\n",
    "    # module.train()\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad_(True)\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "  return torch.sum(y == y_pred) / len(y)"
   ]
  },
  {
   "source": [
    "# Config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 7\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "source": [
    "# Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreSlices (torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, transform):\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = self.transform(Image.open(self.imgs[idx]))\n",
    "\n",
    "        #get the root name of the file (no file extension) and extract the label\n",
    "        label = int(os.path.splitext(os.path.basename(self.imgs[idx]))[0].split(\"_\")[-1])\n",
    "        \n",
    "        return img, torch.tensor(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]), #TODO get values from dataset\n",
    "    #augmentation\n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]), #TODO get values from dataset\n",
    "])\n",
    "\n",
    "#get list of all images in directories\n",
    "image_dirs = [\"data/slices/\"]#,\"data/Core Images/21-20a- 1/\",\"data/Core Images/42-29- 6/\",\"data/Core Images/206-01- 2/\"]\n",
    "\n",
    "images = list_file_paths(image_dirs)\n",
    "\n",
    "images_train, images_val = train_test_split(images, train_size=0.8)\n",
    "images_val, images_test = train_test_split(images_val, train_size=0.5)\n",
    "\n",
    "slices = {}\n",
    "slices[\"train\"] = CoreSlices(images_train, train_transform)\n",
    "slices[\"val\"] = CoreSlices(images_train, train_transform)\n",
    "slices[\"test\"] = CoreSlices(images_train, test_transform)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Dataloaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders[\"train\"] = torch.utils.data.DataLoader(slices[\"train\"], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)\n",
    "dataloaders[\"val\"] = torch.utils.data.DataLoader(slices[\"val\"], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)\n",
    "dataloaders[\"test\"] = torch.utils.data.DataLoader(slices[\"test\"], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=2048, out_features=  N_CLASSES),\n",
    ")\n",
    "\n",
    "freeze(model.conv1)\n",
    "freeze(model.bn1)\n",
    "freeze(model.maxpool)\n",
    "freeze(model.layer1)\n",
    "freeze(model.layer2)\n",
    "freeze(model.layer3)\n",
    "freeze(model.layer4)\n",
    "freeze(model.fc)\n",
    "freeze(model.avgpool)"
   ]
  },
  {
   "source": [
    "# Runner"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, model, optimizer, criterion, device, summarywriter=None, epoch_scheduler=None, batch_scheduler=None):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.summarywriter = summarywriter\n",
    "        self.epoch_scheduler = epoch_scheduler\n",
    "        self.batch_scheduler = batch_scheduler\n",
    "\n",
    "        #TODO implement the class based metrics used int the AiCourse notebooks\n",
    "        self.metrics = {\n",
    "            \"train\":{\n",
    "                \"loss\":0,\n",
    "                \"accuracy\":0\n",
    "            },\n",
    "            \"val\":{\n",
    "                \"loss\":0,\n",
    "                \"accuracy\":0\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def predict(self, outputs):\n",
    "      return torch.argmax(outputs, dim=1)\n",
    "\n",
    "    def predict_proba(self, outputs):\n",
    "        return torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "    def train(self, dataloader, epoch):\n",
    "\n",
    "        #switch to train mode\n",
    "        self.model.train()\n",
    "        train_step = 0\n",
    "        \n",
    "        #loop over each sample\n",
    "        for X,y in dataloader:\n",
    "            train_step+=1\n",
    "\n",
    "            X,y = X.to(self.device), y.to(self.device)\n",
    "            outputs = model.forward(X)\n",
    "\n",
    "            y_pred = self.predict(outputs)\n",
    "            self.metrics[\"train\"][\"accuracy\"] += accuracy(y_pred, y)\n",
    "\n",
    "            # back prop\n",
    "            loss = self.criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            #run scheduler per step\n",
    "            if self.batch_scheduler:\n",
    "                self.batch_scheduler.step()\n",
    "            \n",
    "            self.metrics[\"train\"][\"loss\"] += loss\n",
    "\n",
    "            yield train_step, loss\n",
    "\n",
    "        #calculate final metrics \n",
    "        self.metrics[\"train\"][\"loss\"] = self.metrics[\"train\"][\"loss\"] / train_step\n",
    "        self.metrics[\"train\"][\"accuracy\"] = self.metrics[\"train\"][\"accuracy\"] / train_step\n",
    "\n",
    "        #output to tensorboard\n",
    "        if summarywriter:\n",
    "            self.summarywriter.add_scaler(\"loss/training\", self.metrics[\"train\"][\"loss\"], epoch)\n",
    "            self.summarywriter.add_scaler(\"accuracy/training\", self.metrics[\"train\"][\"accuracy\"], epoch)\n",
    "\n",
    "        #run scheduler per epoch\n",
    "        if self.epoch_scheduler:\n",
    "                    self.epoch_scheduler.step()\n",
    "    \n",
    "    def evaluate(self, dataloader, epoch):\n",
    "\n",
    "        self.model.eval()\n",
    "        val_step = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X,y in dataloader:\n",
    "                val_step+=1\n",
    "\n",
    "                X,y = X.to(self.device), y.to(self.device)\n",
    "                outputs = model.forward(X)\n",
    "\n",
    "                y_pred = self.predict(outputs)\n",
    "                self.metrics[\"val\"][\"accuracy\"] += accuracy(y_pred, y)\n",
    "\n",
    "                loss = self.criterion(outputs, y)\n",
    "                self.metrics[\"val\"][\"loss\"] += loss\n",
    "\n",
    "                yield val_step, loss\n",
    "\n",
    "        #calculate final metrics \n",
    "        self.metrics[\"val\"][\"loss\"] = self.metrics[\"val\"][\"loss\"] / train_step\n",
    "        self.metrics[\"val\"][\"accuracy\"] = self.metrics[\"val\"][\"accuracy\"] / train_step\n",
    "\n",
    "        #output to tensorboard\n",
    "        if summarywriter:\n",
    "            self.summarywriter.add_scaler(\"loss/evaluation\", self.metrics[\"evaluation\"][\"loss\"], epoch)\n",
    "            self.summarywriter.add_scaler(\"accuracy/evaluation\", self.metrics[\"evaluation\"][\"accuracy\"], epoch)\n",
    "\n",
    "    def fit(self, epochs, dataloaders):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"EPOCH {epoch+1}\")\n",
    "            #TRAIN\n",
    "            for step, loss in self.train(dataloaders[\"train\"], epoch):\n",
    "                print(f\"Training - Step: {step} Loss: {loss.item()}\")\n",
    "            \n",
    "            #EVALUATE\n",
    "            for step, loss in self.evaluate(dataloaders[\"validation\"], epoch):\n",
    "                print(f\"Validation - Step: {step}| Loss: {loss.item()}\")\n",
    "        "
   ]
  },
  {
   "source": [
    "# Run and Tensorboard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summarywriter = SummaryWriter()\n",
    "runner = Runner(model, optimizer, criterion, device, summarywriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EPOCH 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5ec0ebe08131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-6acb93357b33>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, dataloaders)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"EPOCH {epoch+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m#TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training - Step: {step} Loss: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6acb93357b33>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, epoch)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# back prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "runner.fit(epochs, dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  }
 ]
}